{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHAPTER 1 - Your First Web Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL Open\n",
    "\n",
    "'''\n",
    "The urllib.request module defines functions and classes which help in opening\n",
    "URLs (mostly HTTP) in a complex world — basic and digest authentication, redirections, cookies and more.\n",
    "\n",
    "https://docs.python.org/3/library/urllib.request.html#module-urllib.request\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from urllib.request import urlopen\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define URl's \n",
    "Url_EEOC = 'https://www.eeoc.gov/'\n",
    "Url_SSL = 'http://securities.stanford.edu/filings-case.html?id=103772'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get All HTML Code - urlopen()\n",
    "\n",
    "def get_all_html():\n",
    "    html = urlopen(Url)\n",
    "    print(html.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boldest']\n",
      "{'class': ['boldest']}\n"
     ]
    }
   ],
   "source": [
    "# THE BS4 OBJECT\n",
    "\n",
    "'''\n",
    "Object               Bs4 transforms an html page into a tree like structure. There are 4 objects that you will commonly use. \n",
    "Tag                  Corresponds to the html tag. \n",
    "Name                 Every Tag has a name.  Name is accessible by calling tag.name \n",
    "Attributes           Tags have any number of attributes. \n",
    "                     <b id=\"boldest\"> = 'b' is the tag, 'id' is the attribute' attribute is 'boldest' \n",
    "                     You can access a tag’s attributes by treating the tag like a dictionary.\n",
    "                     You can also access directly the dictionary by calling tag.attrs\n",
    "'''\n",
    "\n",
    "# Example of Tag\n",
    "def get_tag():\n",
    "    soup = BeautifulSoup('<b class=\"boldest\">Extremely bold</b>', 'lxml')\n",
    "    tag = soup.b             # 'b' is the tag. \n",
    "    print(type(tag))\n",
    "\n",
    "# Example Get Tag Name   \n",
    "def get_tag_name():\n",
    "    soup = BeautifulSoup('<b class=\"boldest\">Extremely bold</b>', 'lxml')\n",
    "    tag = soup.b              \n",
    "    print(tag.name)     #call tag name. \n",
    "\n",
    "# Example Access Attribute\n",
    "def get_tag_Att():\n",
    "    soup = BeautifulSoup('<b class=\"boldest\">Extremely bold</b>', 'lxml')\n",
    "    tag = soup.b              \n",
    "    print(tag['class'])  #returns 'boldest'\n",
    "    print(tag.attrs)\n",
    "get_tag_Att()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a name=\"__topdoc__\"></a>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Run Beautiful Soup\n",
    "\n",
    "def get_bs4_obj(Url):\n",
    "    html = urlopen(Url)                          # Call urlopn on the url\n",
    "    bsObj = BeautifulSoup(html.read(),'lxml')         # Read the Url into bs4\n",
    "    print(bsObj)                                      # print object\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling exceptions\n",
    "\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "\n",
    "def get_title(url):\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        print(e)\n",
    "    try:\n",
    "        bsObj = BeautifulSoup(html.read(), 'lxml')  \n",
    "        title = bsObj.body.h1\n",
    "    except AttributeError as e:                 #error handling for when a tag could not be found. \n",
    "        return None\n",
    "    return title\n",
    "\n",
    "title = get_title('https://en.wikipedia.org/wiki/Python_(programming_language)')\n",
    "\n",
    "if title == None:\n",
    "    print('Title could not be found')\n",
    "else:\n",
    "    print(title)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
