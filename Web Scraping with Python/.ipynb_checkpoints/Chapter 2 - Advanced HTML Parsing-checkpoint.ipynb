{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 2:  Advanced HTML Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_excel(dataframe, filename):\n",
    "    writer = pd.ExcelWriter(filename+'.xlsx')\n",
    "    dataframe.to_excel(writer, 'Data')\n",
    "    writer.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages   \n",
    "import urllib\n",
    "import bs4\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL Example\n",
    "\n",
    "url_ex = 'http://www.pythonscraping.com/pages/warandpeace.html'\n",
    "url_seekingalpha = 'https://seekingalpha.com/earnings/earnings-call-transcripts'\n",
    "url_conf_call_transcripts = 'http://conferencecalltranscripts.org/?co='\n",
    "url_EEOC = 'https://www.eeoc.gov/'\n",
    "url_War = 'https://www.pythonscraping.com/pages/warandpeace.html'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1.)  Span =       is used in html to change the style of a particular attribute on the page ex: text color. \\n2.)  h1 =         is the first title on the page.  h1 - n = there could be an inumerable number of titles on a page.  \\n3.)  get_text() = strips all tages from the document you are working with and retruns a string containing the text only. \\n                  book says that this should be the last step in any code as its much easier to find what you need with tags. \\n4.)  attributes = for the findall() function, atribute arguments take a Python dictionary of attributes and matches tags \\n                  that contain any of those attributes.   \\n5.)  CSS:         Is the CSS is the language for describing the presentation of Web pages, including colors, layout, and fonts. \\n                  It allows one to adapt the presentation to different types of devices, such as large screens,\\n                  small screens, or printers. CSS is independent of HTML and can be used with any XML-based markup language.\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Terminology\n",
    "'''\n",
    "1.)  Span =       is used in html to change the style of a particular attribute on the page ex: text color. \n",
    "2.)  h1 =         is the first title on the page.  h1 - n = there could be an inumerable number of titles on a page.  \n",
    "3.)  get_text() = strips all tages from the document you are working with and retruns a string containing the text only. \n",
    "                  book says that this should be the last step in any code as its much easier to find what you need with tags. \n",
    "4.)  attributes = for the findall() function, atribute arguments take a Python dictionary of attributes and matches tags \n",
    "                  that contain any of those attributes.   \n",
    "5.)  CSS:         Is the CSS is the language for describing the presentation of Web pages, including colors, layout, and fonts. \n",
    "                  It allows one to adapt the presentation to different types of devices, such as large screens,\n",
    "                  small screens, or printers. CSS is independent of HTML and can be used with any XML-based markup language.\n",
    "6.)               If you only want the text part of a document or tag, you can use the get_text() method. \n",
    "                  It returns all the text in a document or beneath a tag, as a single Unicode string:\n",
    "7.)               Tree - bsObj.body.h1; bsObj is our html page, body is the tag and h1 is the decendent tag for body.\n",
    "                  Using this structure, you can call decendents within the body tag. \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping using CSS Attributes\n",
    "\n",
    "def get_CSS_Attrs(Url):\n",
    "    html = urlopen(Url)\n",
    "    bsOjb = BeautifulSoup(html.read())\n",
    "    # Use bs4 'findAll' function to extract a Python list of nouns by selecting only the text within <span class = 'green'></span>\n",
    "    nameList = bsOjb.findAll('span', {'class':'green'}) #find all takes a dictionary like object for {class : attribute}\n",
    "    for name in nameList:\n",
    "        print(name.get_text())                          #Its unclear where the get_text() command comes from. \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigating Trees\n",
    "\n",
    "def get_bs4_Obj():\n",
    "    html = urlopen('https://www.pythonscraping.com/pages/page3.html')\n",
    "    bsObj = BeautifulSoup(html.read(), 'lxml')\n",
    "    print(bsObj)\n",
    "\n",
    "def get_bs4_Obj_Children():\n",
    "    html = urlopen('https://www.pythonscraping.com/pages/page3.html')\n",
    "    bsObj = BeautifulSoup(html.read(), 'lxml')\n",
    "    for child in bsObj.find('table', {'id':'giftList'}).children:     #Table is our tag. Id is our tag for the attribute.   \n",
    "        print(child)                                                  #children tells python to only obtain teh children of tags\n",
    "                                                                      #You can call 'decendant' to get all decendants of children\n",
    "                                                                      #tags on the web page. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\t\t\t                \t      \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t                \t      \t\t\t\t\t                \t      \t\tINC Research Holdings, Inc.\n",
      "\t\t\t\t                \t      \t\t\t\t\t                \t      \n"
     ]
    }
   ],
   "source": [
    "# Dealing with Siblings\n",
    "\n",
    "def get_siblings():\n",
    "    html = urlopen('https://www.pythonscraping.com/pages/page3.html')\n",
    "    bsObj = BeautifulSoup(html.read(), 'lxml')\n",
    "    \n",
    "    for sibling in bsObj.find('table', {'id':'giftList'}).tr.next_siblings:\n",
    "        print(sibling)               # 'table' is the tag that refers to an actual table on the web page. \n",
    "                                     # 'tr' appears to refer to the rows of the table and is inferior or below the table tag. \n",
    "        \n",
    "def get_siblings_2():\n",
    "    List1 = []\n",
    "    html = urlopen('http://securities.stanford.edu/filings.html')\n",
    "    bsObj = BeautifulSoup(html.read(), 'lxml')\n",
    "    \n",
    "    for x in bsObj.find('tr', {'class':'table-link'}).td:\n",
    "        print(x)\n",
    "        \n",
    "get_siblings_2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
